使用方法
>>help(svm_train)
Help on function svm_train in module svmutil:

svm_train(arg1, arg2=None, arg3=None)
    svm_train(y, x [, options]) -> model | ACC | MSE
    svm_train(prob [, options]) -> model | ACC | MSE
    svm_train(prob, param) -> model | ACC| MSE
    
    Train an SVM model from data (y, x) or an svm_problem prob using
    'options' or an svm_parameter param.
    If '-v' is specified in 'options' (i.e., cross validation)
    either accuracy (ACC) or mean-squared error (MSE) is returned.
    options:
        -s svm_type : set type of SVM (default 0)
            0 -- C-SVC        (multi-class classification)
            1 -- nu-SVC        (multi-class classification)
            2 -- one-class SVM
            3 -- epsilon-SVR    (regression)
            4 -- nu-SVR        (regression)
        -t kernel_type : set type of kernel function (default 2)
            0 -- linear: u'*v
            1 -- polynomial: (gamma*u'*v + coef0)^degree
            2 -- radial basis function: exp(-gamma*|u-v|^2)
            3 -- sigmoid: tanh(gamma*u'*v + coef0)
            4 -- precomputed kernel (kernel values in training_set_file)
        -d degree : set degree in kernel function (default 3)
        -g gamma : set gamma in kernel function (default 1/num_features)
        -r coef0 : set coef0 in kernel function (default 0)
        -c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)
        -n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)
        -p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)
        -m cachesize : set cache memory size in MB (default 100)
        -e epsilon : set tolerance of termination criterion (default 0.001)
        -h shrinking : whether to use the shrinking heuristics, 0 or 1 (default 1)
        -b probability_estimates : whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)
        -wi weight : set the parameter C of class i to weight*C, for C-SVC (default 1)
        -v n: n-fold cross validation mode
        -q : quiet mode (no outputs)

0 -- linear(线性核):
Accuracy = 91.6533% (84047/91701) (classification)
running time :
174.04962028586112
1 -- polynomial(多项式核):
Accuracy = 90.4996% (82989/91701) (classification)
running time :
204.02602104571702
2 -- radial basis function(RBF,径向基核/高斯核):
running time :
188.3169225321575
C(惩罚因子)	Accuracy 
1	92.3796% (84713/91701) (classification)
4	93.0001% (85282/91701) (classification)
7	94.1048% (86295/91701)
10	94.8681% (86995/91701)
15	95.6685% (87729/91701)
20	96.0633% (88091/91701)
30	96.6031% (88586/91701)
50	97.1734% (89109/91701)
100	97.5704% (89473/91701)
200	97.8125% (89695/91701)
500	97.771% (89657/91701)   overfit
1000	97.6685% (89563/91701) overfit

3 -- sigmoid(S型核):
Accuracy = 91.3163% (83738/91701) (classification)
running time :
212.73236760468308

总结：

参考：
http://www.cnblogs.com/Finley/p/5329417.html
Source code for libsvm.svmutil
http://www-lium.univ-lemans.fr/sidekit/_modules/libsvm/svmutil.html